import lancedb from 'vectordb';
import { readVault } from '../lib/vault-reader.js';
import { chunkText } from '../lib/chunker.js';
import { initEmbeddings, generateEmbedding } from '../lib/embeddings.js';
import dotenv from 'dotenv';

dotenv.config();

const VAULT_PATH = process.env.VAULT_PATH;
const DB_PATH = './lancedb';
const TABLE_NAME = 'ben_vault';
const CHUNK_SIZE = parseInt(process.env.CHUNK_SIZE) || 500;
const CHUNK_OVERLAP = parseInt(process.env.CHUNK_OVERLAP) || 50;

async function indexVault() {
  console.log('ğŸš€ Starting vault indexing...\n');
  
  console.log('ğŸ“¦ Loading embedding model...');
  await initEmbeddings(process.env.EMBEDDING_MODEL);
  
  console.log('ğŸ”— Connecting to LanceDB...');
  const db = await lancedb.connect(DB_PATH);
  
  console.log(`\nğŸ“– Reading vault from: ${VAULT_PATH}`);
  console.log('ğŸ“‚ Processing profiles: public');
  const files = await readVault(VAULT_PATH, ['public']);
  
  if (files.length === 0) {
    console.error('\nâŒ No files found!');
    process.exit(1);
  }
  
  console.log(`âœ” Found ${files.length} files\n`);
  
  const allData = [];
  let processedFiles = 0;
  let filesWithDates = 0;
  
  for (const file of files) {
    processedFiles++;
    const hasDate = file.metadata.date ? 'ğŸ“…' : '  ';
    console.log(`[${processedFiles}/${files.length}] ${hasDate} Processing: ${file.name} (${file.metadata.contentType})`);
    
    if (file.metadata.date) {
      filesWithDates++;
      console.log(`  â”œâ”€ Date: ${file.metadata.date}`);
    }
    
    const chunks = chunkText(file.content, CHUNK_SIZE, CHUNK_OVERLAP);
    console.log(`  â”œâ”€ Created ${chunks.length} chunks`);
    console.log(`  â”œâ”€ Generating embeddings...`);
    
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      const embedding = await generateEmbedding(chunk);
      
      allData.push({
        id: `${file.name}_chunk_${i}`,
        text: chunk,
        vector: embedding,
        file: file.name,
        filePath: file.metadata.filePath,
        profile: file.metadata.profile,
        directory: file.metadata.directory,
        source: file.metadata.source || '',
        date: file.metadata.date || '',  // NEW: Store date
        contentType: file.metadata.contentType,
        chunkIndex: i,
        totalChunks: chunks.length
      });
    }
    
    console.log(`  â””â”€ Indexed ${chunks.length} chunks\n`);
  }
  
  console.log('ğŸ’¾ Creating LanceDB table...');
  
  try {
    await db.dropTable(TABLE_NAME);
  } catch (e) {
    // Table doesn't exist, that's fine
  }
  
  await db.createTable(TABLE_NAME, allData);
  
  console.log('\nâœ… Indexing complete!');
  console.log(`ğŸ“Š Statistics:`);
  console.log(`   - Files processed: ${processedFiles}`);
  console.log(`   - Files with dates: ${filesWithDates} (${Math.round(filesWithDates/processedFiles*100)}%)`);
  console.log(`   - Total chunks: ${allData.length}`);
  console.log(`   - Average chunks per file: ${(allData.length / processedFiles).toFixed(1)}`);
  console.log(`\nğŸ’¾ Vector database location: ${DB_PATH}`);
  console.log(`\nğŸ’¡ Tip: For date-based queries, use terms like "recent", "latest", or "newest"`);
}

indexVault().catch(error => {
  console.error('âŒ Error during indexing:', error);
  process.exit(1);
});
